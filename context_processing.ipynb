{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# Load the Wikipedia article titles into a set for efficient lookup\n",
    "wiki_titles = set()\n",
    "with gzip.open(\"enwiki-latest-all-titles-in-ns0.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for title in f:\n",
    "        title = title.strip()\n",
    "        title = title.replace(\"_\", \" \")\n",
    "        wiki_titles.add(title.strip())\n",
    "\n",
    "# Check if a person name has a Wikipedia article associated with it\n",
    "person_name = \"Bill Clinton\"\n",
    "if person_name in wiki_titles:\n",
    "    print(f\"{person_name} has a Wikipedia article!\")\n",
    "else:\n",
    "    print(f\"{person_name} does not have a Wikipedia article.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# set the language for the Wikipedia API\n",
    "wikipedia.set_lang(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_2014'\n",
    "df = pd.read_csv(f'{filename}_with_topics_full.csv')\n",
    "# df = pd.read_json(filename)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    title = row['title']\n",
    "    print(title)\n",
    "\n",
    "    # ask for user input\n",
    "    while True:\n",
    "        usertext = input(\"Enter a person's name: \")\n",
    "        # check if the title is in the set\n",
    "        if usertext in wiki_titles:\n",
    "            print(f\"{usertext} has a Wikipedia article!\")\n",
    "            break\n",
    "        elif usertext == 'q':\n",
    "            break\n",
    "        else:\n",
    "            titles = wikipedia.search(usertext)\n",
    "            print(f\"{usertext} does not have a Wikipedia article. Did you mean: {titles}?\")\n",
    "\n",
    "    df.at[index, 'wiki'] = usertext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['title', 'wiki']].to_csv(f'{filename}_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv(f'{filename}_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "# Initialize the Wikipedia API\n",
    "wiki_api = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the first paragraph from the summary of the Wikipedia article\n",
    "for index, row in df_wiki.iterrows():\n",
    "    title = row['title']\n",
    "    wiki = row['wiki']\n",
    "    if wiki in ['Request', 'Story']:\n",
    "        df_wiki.at[index, 'summary'] = np.nan\n",
    "        continue\n",
    "    try:\n",
    "        summary = wiki_api.page(wiki).summary.split('\\n')[0]\n",
    "        df_wiki.at[index, 'summary'] = summary\n",
    "        # print(f\"{wiki} summary: {summary}\")\n",
    "    except:\n",
    "        print(f\"Error: {wiki} does not have a summary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki.to_csv(f'{filename}_wiki_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv(f'{filename}_wiki_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan summaries with empty strings\n",
    "df_wiki['summary'] = df_wiki['summary'].fillna('')\n",
    "\n",
    "# only keep as many sentences as needed to have a summary that is more than 50 tokens\n",
    "def get_first_sentence(summary):\n",
    "    sentences = nltk.sent_tokenize(summary)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if len(nltk.word_tokenize(' '.join(sentences[:i]))) > 50:\n",
    "            return ' '.join(sentences[:i])\n",
    "    return summary\n",
    "\n",
    "df_wiki['summary'] = df_wiki['summary'].apply(get_first_sentence)\n",
    "\n",
    "# remove non-engish characters\n",
    "df_wiki['summary'] = df_wiki['summary'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
    "\n",
    "# collapse multiple spaces into one\n",
    "df_wiki['summary'] = df_wiki['summary'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki.to_csv(f'{filename}_wiki_summary_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv(f'{filename}_wiki_summary_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess title\n",
    "# replace 'iama' in any variation of capital/lowercase letters with 'I am a'\n",
    "df_wiki['title'] = df_wiki['title'].apply(lambda x: re.sub(r'iama ', 'I am a ', x, flags=re.IGNORECASE))\n",
    "\n",
    "# replace ' ama' in any variation of capital/lowercase letters with ''\n",
    "df_wiki['title'] = df_wiki['title'].apply(lambda x: re.sub(r' ama', '', x, flags=re.IGNORECASE))\n",
    "\n",
    "# replace ' aua' in any variation of capital/lowercase letters with ''\n",
    "df_wiki['title'] = df_wiki['title'].apply(lambda x: re.sub(r' aua', '', x, flags=re.IGNORECASE))\n",
    "\n",
    "# replace '&amp;' with '&'\n",
    "df_wiki['title'] = df_wiki['title'].apply(lambda x: re.sub(r'&amp;', '&', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a list of non-alphanumeric characters in the title\n",
    "non_alphanumeric = df_wiki['title'].apply(lambda x: re.findall(r'[^a-zA-Z0-9 ]', x))\n",
    "# merge all the lists into one list\n",
    "non_alphanumeric = [item for sublist in non_alphanumeric for item in sublist]\n",
    "# remove duplicates\n",
    "non_alphanumeric = list(set(non_alphanumeric))\n",
    "\n",
    "safe_characters = [' ', '&', '-', \"'\", '.', ',', '!', '?', ':', ';', '(', ')', '[', ']', '/', '\"', '%', '$', '@', '#', '+', '=']\n",
    "\n",
    "# remove safe characters from the list of non-alphanumeric characters\n",
    "for char in safe_characters:\n",
    "    if char in non_alphanumeric:\n",
    "        non_alphanumeric.remove(char)\n",
    "\n",
    "# remove non-alphanumeric characters from the title\n",
    "def remove_non_alphanumeric(title):\n",
    "    for char in non_alphanumeric:\n",
    "        title = title.replace(char, '')\n",
    "    return title\n",
    "\n",
    "df_wiki['title'] = df_wiki['title'].apply(remove_non_alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to truncate after 'Ask' in the title\n",
    "def truncate_title(title):\n",
    "    # find the index of 'Ask' in the title\n",
    "    index = title.lower().find('ask ')\n",
    "    # if 'Ask' is not found, return the original title\n",
    "    if index == -1:\n",
    "        return title\n",
    "    # otherwise, return the title truncated after 'Ask'\n",
    "    else:\n",
    "        return title[:index]\n",
    "    \n",
    "df_wiki['title'] = df_wiki['title'].apply(truncate_title)\n",
    "\n",
    "# remove leading and trailing whitespace\n",
    "df_wiki['title'] = df_wiki['title'].apply(lambda x: x.strip())\n",
    "\n",
    "# replace consecutive punctuation with the last punctuation\n",
    "df_wiki['title'] = df_wiki['title'].apply(lambda x: re.sub(r'[.,?!:;]+(?=[.,?!:;])', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki.to_csv(f'{filename}_wiki_summary_title_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv(f'{filename}_wiki_summary_title_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan summary and title with empty strings\n",
    "df_wiki['summary'] = df_wiki['summary'].fillna('')\n",
    "df_wiki['title'] = df_wiki['title'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the title and summary into one column: context\n",
    "df_wiki['context'] = df_wiki.apply(lambda x: x['title'] + ' ' + x['summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make context empty string if there is no summary\n",
    "df_wiki['context'] = df_wiki.apply(lambda x: '' if x['summary'] == '' else x['context'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki[['context', 'title']].to_csv(f'{filename}_with_context.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final582",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
