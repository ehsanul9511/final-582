{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from openai) (2.29.0)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (338 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-macosx_11_0_arm64.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp39-cp39-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: multidict, frozenlist, attrs, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import openai\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# sleep import\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data_2015_to_2021.csv')\n",
    "df = pd.read_csv('data_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['comments'][20]\n",
    "comments = ast.literal_eval(comments)\n",
    "\n",
    "# each comment is a dictionary with keys: body and score\n",
    "# sort comments by score descending\n",
    "comments = sorted(comments, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# filter out comments that have no ? in body\n",
    "comments = [comment for comment in comments if '?' in comment['body']]\n",
    "\n",
    "# filter out comments that have more than 15 words or less than 5 words\n",
    "comments = [comment for comment in comments if len(nltk.word_tokenize(comment['body'])) > 5 and len(nltk.word_tokenize(comment['body'])) < 50]\n",
    "\n",
    "# filter out comments that have score less than 10\n",
    "comments = [comment for comment in comments if comment['score'] > 10]\n",
    "\n",
    "# filter out comments that have https in body\n",
    "comments = [comment for comment in comments if 'https' not in comment['body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683251857.796414\n",
      "1683251858.802718\n"
     ]
    }
   ],
   "source": [
    "print(time.time())\n",
    "sleep(1)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 row\n",
      "2 row\n",
      "3 row\n",
      "4 row\n",
      "5 row\n",
      "6 row\n",
      "7 row\n",
      "8 row\n",
      "9 row\n",
      "10 row\n",
      "11 row\n",
      "12 row\n",
      "13 row\n",
      "14 row\n",
      "15 row\n",
      "16 row\n",
      "17 row\n",
      "18 row\n",
      "19 row\n",
      "20 row\n",
      "21 row\n",
      "22 row\n",
      "23 row\n",
      "24 row\n",
      "25 row\n",
      "26 row\n",
      "27 row\n",
      "28 row\n",
      "29 row\n",
      "30 row\n",
      "31 row\n",
      "32 row\n",
      "33 row\n",
      "34 row\n",
      "35 row\n",
      "36 row\n",
      "37 row\n",
      "38 row\n",
      "39 row\n",
      "40 row\n",
      "41 row\n",
      "42 row\n",
      "43 row\n",
      "44 row\n",
      "45 row\n",
      "46 row\n",
      "47 row\n",
      "48 row\n",
      "49 row\n",
      "50 row\n",
      "51 row\n",
      "52 row\n",
      "53 row\n",
      "54 row\n",
      "55 row\n",
      "56 row\n",
      "57 row\n",
      "58 row\n",
      "59 row\n",
      "60 row\n",
      "61 row\n",
      "62 row\n",
      "63 row\n",
      "64 row\n",
      "65 row\n",
      "66 row\n",
      "67 row\n",
      "68 row\n",
      "69 row\n",
      "70 row\n"
     ]
    }
   ],
   "source": [
    "# loop through each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    print(f'{index+1} row')\n",
    "    comments = row['comments']\n",
    "    comments = ast.literal_eval(comments)\n",
    "    comments = sorted(comments, key=lambda x: x['score'], reverse=True)\n",
    "    comments = [comment for comment in comments if '?' in comment['body']]\n",
    "    comments = [comment for comment in comments if len(nltk.word_tokenize(comment['body'])) > 5 and len(nltk.word_tokenize(comment['body'])) < 50]\n",
    "    comments = [comment for comment in comments if comment['score'] > 10]\n",
    "    comments = [comment for comment in comments if 'http' not in comment['body']]\n",
    "    # for i, comment in enumerate(comments):\n",
    "    #     query = f'Describe the topic of the question below in a single word/phrase. \\n\\nQ: {comment[\"body\"]}\\n\\nA:'\n",
    "    #     t = time.time()\n",
    "    #     response = openai.Completion.create(\n",
    "    #         model=\"text-davinci-003\",\n",
    "    #         prompt=query,\n",
    "    #         max_tokens=5,\n",
    "    #         temperature=0\n",
    "    #     )\n",
    "    #     time_left = 1.0 - (time.time() - t)\n",
    "    #     if time_left > 0:\n",
    "    #         sleep(time_left)\n",
    "    #     topic = response['choices'][0]['text']\n",
    "    #     # print(f'{i+1}. {topic}')\n",
    "    #     comments[i]['topic'] = topic\n",
    "    df.at[index, 'comments'] = comments\n",
    "    # df.to_csv('data_2015_to_2021_with_cherry_picked_comments.csv', index=False)\n",
    "    df.to_csv('data_2014_with_cherry_picked_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_2015_to_2021_with_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['from_id', 'secure_media', 'url', 'subreddit_id', 'from_kind',\n",
       "       'created', 'stickied', 'score', 'edited', 'quarantine',\n",
       "       'author_flair_css_class', 'num_comments', 'saved', 'over_18',\n",
       "       'gilded', 'link_flair_css_class', 'id', 'archived', 'from',\n",
       "       'author', 'is_self', 'link_flair_text', 'permalink', 'selftext',\n",
       "       'media', 'ups', 'retrieved_on', 'created_utc', 'author_flair_text',\n",
       "       'media_embed', 'subreddit', 'domain', 'hide_score', 'downs',\n",
       "       'thumbnail', 'distinguished', 'title', 'secure_media_embed',\n",
       "       'retrieved_utc', 'updated_utc', 'edited_on', 'utc_datetime_str',\n",
       "       'comments', 'post_hint', 'preview', 'locked', 'contest_mode',\n",
       "       'spoiler', 'hidden', 'brand_safe', 'suggested_sort', 'can_gild',\n",
       "       'thumbnail_width', 'thumbnail_height', 'view_count', 'is_video',\n",
       "       'approved_at_utc', 'banned_at_utc', 'is_crosspostable',\n",
       "       'num_crossposts', 'parent_whitelist_status', 'whitelist_status',\n",
       "       'is_reddit_media_domain', 'pinned', 'subreddit_type',\n",
       "       'author_cakeday', 'no_follow', 'send_replies',\n",
       "       'subreddit_subscribers', 'approved_by',\n",
       "       'author_flair_background_color', 'author_flair_richtext',\n",
       "       'author_flair_template_id', 'author_flair_text_color',\n",
       "       'author_flair_type', 'category', 'content_categories',\n",
       "       'is_original_content', 'likes', 'link_flair_background_color',\n",
       "       'link_flair_richtext', 'link_flair_template_id',\n",
       "       'link_flair_text_color', 'link_flair_type', 'media_only',\n",
       "       'mod_reports', 'num_reports', 'post_categories', 'pwls',\n",
       "       'removal_reason', 'report_reasons', 'rte_mode', 'selftext_html',\n",
       "       'user_reports', 'wls', 'previous_visits', 'author_created_utc',\n",
       "       'author_fullname', 'is_meta', 'subreddit_name_prefixed',\n",
       "       'author_patreon_flair', 'gildings', 'is_robot_indexable',\n",
       "       'all_awardings', 'total_awards_received', 'allow_live_comments',\n",
       "       'discussion_type', 'author_premium', 'awarders', 'removed_by',\n",
       "       'removed_by_category', 'treatment_tags', 'is_created_from_ads_ui',\n",
       "       'top_awarded_type', 'upvote_ratio'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey, I'm Kevin Parker. Pretty excited to be doing this! (have been wanting to for a long time).\\n\\nI record music under the name Tame Impala. When you add 4 of my friends we're a band that tours the world together. \\nI've made 3 albums, 1 yet to be released. Ummmm not sure what else to add. We've won some WAMIs, some ARIAs and got nominated for a grammy, whatever that counts for. Once Danny de Vito watched us from side of stage.\\n\\nI am painting my wall pink, check it out:\\n\\nHere is proof it is me https://www.facebook.com/tameimpala/posts/10152896471795777\\n\\nAnd photographic proof http://imgur.com/TNtMSt4\\n\\nI want to tell you all about the new album, but I don't want to spoil it!!!! So ask whatever you like but I'm going to have to restrain myself.\\n\\nAsk me anything, nothing is taboo, or too dumb or too intellectual.\\n\\nI'll try and get through as much as I can, sorry if I take ages to type answers, I type with like, 2 and a half fingers.\\n\\nOK hit me!\\n\\n\\n**UPDATE**\\n\\nWell I have to go now....Thanks so much for being here and making me feel important. I have to go and do some interviews that will almost certainly not be as fun as this. I wish all press could be AMAs! Alas this is not the case.\\nA man can dream though..... A man can dream.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# set the language for the Wikipedia API\n",
    "wikipedia.set_lang(\"en\")\n",
    "\n",
    "# enter the search query\n",
    "query = \"SuicideGirls\"\n",
    "\n",
    "# search for the query and get the list of matching titles\n",
    "titles = wikipedia.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SuicideGirls',\n",
       " 'Alt porn',\n",
       " 'Sex-positive movement',\n",
       " 'Gavin Rossdale',\n",
       " 'Paul Lieberstein',\n",
       " 'Zia McCabe',\n",
       " 'Jared Padalecki',\n",
       " 'Josh Freese',\n",
       " 'Dave England',\n",
       " 'Joanna Angel']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda/envs/final582/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[70], line 1\u001b[0m\n    ast.literal_eval(df['title'][24])\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda/envs/final582/lib/python3.9/ast.py:62\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda/envs/final582/lib/python3.9/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    We are the team behind Cities: Skylines, ask us anything!\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ast.literal_eval(df['comments'][24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from wikipedia) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ehsanulkabir/miniconda/envs/final582/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=32a2e6b4ba0039e2018b4c1dfa0c50dc2a7594c68bba8d42969425395adf4c8b\n",
      "  Stored in directory: /Users/ehsanulkabir/Library/Caches/pip/wheels/c2/46/f4/caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1 wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# set the language for the Wikipedia API\n",
    "wikipedia.set_lang(\"en\")\n",
    "\n",
    "# enter the search query\n",
    "query = \"price is right\"\n",
    "\n",
    "# search for the query and get the list of matching titles\n",
    "titles = wikipedia.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Price Is Right',\n",
       " 'The Price Is Right models',\n",
       " 'List of The Price Is Right pricing games',\n",
       " 'The Price Is Right (1956 American game show)',\n",
       " 'The Price Is Right (franchise)',\n",
       " 'The Price Is Right (disambiguation)',\n",
       " 'The Price Is Right (British game show)',\n",
       " 'The Price Is Right Live!',\n",
       " 'Holly Hallstrom',\n",
       " 'Kathleen Bradley']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22246\n"
     ]
    }
   ],
   "source": [
    "# count the total number of comments\n",
    "total_comments = 0\n",
    "for index, row in df.iterrows():\n",
    "    total_comments += len(row['comments'])\n",
    "\n",
    "print(total_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, comment in enumerate(comments):\n",
    "    query = f'Describe the topic of the question below in a single word/phrase. \\n\\nQ: {comment[\"body\"]}\\n\\nA:'\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=query,\n",
    "        max_tokens=5,\n",
    "        temperature=0\n",
    "    )\n",
    "    topic = response['choices'][0]['text']\n",
    "    print(f'{i+1}. {topic}')\n",
    "    comments[i]['topic'] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    Describe the topic of the question below in a single word/phrase.\n",
    "\n",
    "    What are your thoughts on how media conglomerates influence popularity and dictate who gets played? How much of an artist's message is controlled?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Describe the topic of the question below in a single word/phrase. \\n\\nQ: What was meeting with Gaddadfi about? \\n\\nA:'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=query,\n",
    "  max_tokens=15,\n",
    "  temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7Buy9p8vIuPVoFNWeEefKYhzda35x at 0x12fa0dbd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" With Gaddadfi, there was a lot of discussion about possible solutions\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683074953,\n",
       "  \"id\": \"cmpl-7Buy9p8vIuPVoFNWeEefKYhzda35x\",\n",
       "  \"model\": \"text-ada-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 15,\n",
       "    \"prompt_tokens\": 35,\n",
       "    \"total_tokens\": 50\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prison release and neo-nazi movements.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0][\"message\"][\"content\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final582",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
